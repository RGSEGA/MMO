{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-1id2vR-izk"
   },
   "source": [
    "# Рубежный контроль №2\n",
    "\n",
    "## Сергеев М.К. ИУ5-22М\n",
    "## Тема: Методы обработки текстов\n",
    "## Решение задачи классификации текстов.\n",
    "\n",
    "### Классификатор 1: RandomForestClassifier \n",
    "### Классификатор 2: Complement Naive Bayes (CNB)\n",
    "\n",
    "- Для каждого метода необходимо оценить качество классификации\n",
    "- Сделать вывод о том, какой вариант векторизации признаков в паре с каким классификатором показал лучшее качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e0ljTHHCBcqT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, NuSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
    "\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gIYiWd9_-jAJ"
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
    "data = newsgroups['data']\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAWtw3D-Ja0p"
   },
   "source": [
    "## Анализируем датасет и готовим категориальный признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g8-yQbdBBMZS"
   },
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "hUKC_jYqPaNK",
    "outputId": "225d3eaf-378f-4edb-9828-48d5aa4b26d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 34118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(data)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "mLVpI5Z2PaNN",
    "outputId": "ebd265f9-719a-4388-a035-439dc85e9715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rych=27180\n",
      "festival=13876\n",
      "ed=12325\n",
      "ac=4289\n",
      "uk=31720\n",
      "hawkes=15898\n",
      "subject=29644\n",
      "3ds=2362\n",
      "where=33286\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[1:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "h70hGAtOPaNO",
    "outputId": "fb22245e-69d6-44fa-a65f-58596743ae6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2034x34118 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 323433 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = vocabVect.transform(data)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cC4XxuviPaNP"
   },
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "qX7gkH71PaNQ",
    "outputId": "03f6f25a-66df-4a52-c2f0-d102ff0fdcad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
      "                            '000000': 4, '000005102000': 5, '000021': 6,\n",
      "                            '000062david42': 7, '0000vec': 8, '0001': 9,\n",
      "                            '000100255pixel': 10, '000406': 11, '00041032': 12,\n",
      "                            '0004136': 13, '0004246': 14, '0004422': 15,\n",
      "                            '00044513': 16, '0004847546': 17, '0005': 18,\n",
      "                            '0007': 19, '00090711': 20, '000usd': 21,\n",
      "                            '0010580b': 22, '001125': 23, '0012': 24,\n",
      "                            '001200201pixel': 25, '001428': 26, '001555': 27,\n",
      "                            '001718': 28, '001757': 29, ...})\n",
      "Модель для классификации - RandomForestClassifier()\n",
      "Accuracy = 0.8731563421828908\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
      "                            '000000': 4, '000005102000': 5, '000021': 6,\n",
      "                            '000062david42': 7, '0000vec': 8, '0001': 9,\n",
      "                            '000100255pixel': 10, '000406': 11, '00041032': 12,\n",
      "                            '0004136': 13, '0004246': 14, '0004422': 15,\n",
      "                            '00044513': 16, '0004847546': 17, '0005': 18,\n",
      "                            '0007': 19, '00090711': 20, '000usd': 21,\n",
      "                            '0010580b': 22, '001125': 23, '0012': 24,\n",
      "                            '001200201pixel': 25, '001428': 26, '001555': 27,\n",
      "                            '001718': 28, '001757': 29, ...})\n",
      "Модель для классификации - ComplementNB()\n",
      "Accuracy = 0.9523107177974435\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
      "                            '000000': 4, '000005102000': 5, '000021': 6,\n",
      "                            '000062david42': 7, '0000vec': 8, '0001': 9,\n",
      "                            '000100255pixel': 10, '000406': 11, '00041032': 12,\n",
      "                            '0004136': 13, '0004246': 14, '0004422': 15,\n",
      "                            '00044513': 16, '0004847546': 17, '0005': 18,\n",
      "                            '0007': 19, '00090711': 20, '000usd': 21,\n",
      "                            '0010580b': 22, '001125': 23, '0012': 24,\n",
      "                            '001200201pixel': 25, '001428': 26, '001555': 27,\n",
      "                            '001718': 28, '001757': 29, ...})\n",
      "Модель для классификации - RandomForestClassifier()\n",
      "Accuracy = 0.8751229105211406\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
      "                            '000000': 4, '000005102000': 5, '000021': 6,\n",
      "                            '000062david42': 7, '0000vec': 8, '0001': 9,\n",
      "                            '000100255pixel': 10, '000406': 11, '00041032': 12,\n",
      "                            '0004136': 13, '0004246': 14, '0004422': 15,\n",
      "                            '00044513': 16, '0004847546': 17, '0005': 18,\n",
      "                            '0007': 19, '00090711': 20, '000usd': 21,\n",
      "                            '0010580b': 22, '001125': 23, '0012': 24,\n",
      "                            '001200201pixel': 25, '001428': 26, '001555': 27,\n",
      "                            '001718': 28, '001757': 29, ...})\n",
      "Модель для классификации - ComplementNB()\n",
      "Accuracy = 0.9341199606686331\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [RandomForestClassifier(), ComplementNB()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sBd_kZLPaNR"
   },
   "source": [
    "# Лучшая точность была у CountVectorizer c ComplementNB - 0.952"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "РК2 Широков.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "bbdcf83d58750803bddb0838f4afd2350dc6ac29aa7aec92f3be190ea6031456"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
